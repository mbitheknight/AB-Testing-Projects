{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ec4403-5c81-433e-a329-e8652b2bcdce",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de2f007-60cc-444c-936a-fa5108641ef5",
   "metadata": {},
   "source": [
    "# A/B Testing Overview\n",
    "\n",
    "## 1. What is A/B Testing?\n",
    "- **Definition**: A/B testing is a method of comparing two versions of a variable (A and B) to determine which one performs better.\n",
    "- **Purpose**: Used to test changes to a web page, app, or product to optimize for a desired outcome (e.g., click-through rate, conversion rate).\n",
    "\n",
    "## 2. Key Terminology\n",
    "- **Hypothesis**: A prediction about which version (A or B) will perform better.\n",
    "- **Control (A)**: The original version that serves as a baseline.\n",
    "- **Variant (B)**: The modified version being tested against the control.\n",
    "- **Conversion**: The desired action (e.g., signing up, purchasing).\n",
    "- **Conversion Rate**: Percentage of users who complete the conversion out of total visitors.\n",
    "\n",
    "## 3. Steps in A/B Testing\n",
    "1. **Define Goal**: What metric are you trying to improve?\n",
    "2. **Identify Hypothesis**: State what you think will improve with the change.\n",
    "3. **Determine Sample Size**: How many participants are needed for statistically valid results?\n",
    "4. **Divide Sample**: Randomly assign users to either group A or group B.\n",
    "5. **Run Test**: Display each version and collect data on user actions.\n",
    "6. **Analyze Results**: Compare conversion rates and use statistical tests to determine significance.\n",
    "\n",
    "## 4. Statistical Analysis\n",
    "- **Significance Level (α)**: Commonly set at 0.05; represents the probability of rejecting the null hypothesis when it's true.\n",
    "- **P-Value**: Shows the probability that observed results are due to chance. A p-value < α suggests the result is statistically significant.\n",
    "- **Confidence Interval (CI)**: Range within which the true effect size is expected to lie with a given confidence level (e.g., 95%).\n",
    "\n",
    "## 5. Types of Hypothesis Tests\n",
    "- **Two-Tailed Test**: Used when you want to detect any difference in performance.\n",
    "- **One-Tailed Test**: Used when you expect a specific direction of improvement.\n",
    "\n",
    "## 6. Metrics to Measure\n",
    "- **Absolute Conversion Rate**: (Conversions / Total visitors) x 100%\n",
    "- **Relative Conversion Rate**: (Conversion Rate B - Conversion Rate A) / Conversion Rate A x 100%\n",
    "- **Lift**: Improvement seen in variant B over control A.\n",
    "\n",
    "## 7. Tools for A/B Testing\n",
    "- **Common Tools**: Google Optimize, Optimizely, VWO, and custom implementations in Python, R, etc.\n",
    "\n",
    "## 8. Best Practices\n",
    "- **Only Test One Variable at a Time**: Isolate the variable for reliable results.\n",
    "- **Ensure Randomization**: Randomly assign users to prevent bias.\n",
    "- **Monitor Duration**: Run tests long enough to capture meaningful data.\n",
    "- **Avoid Peeking**: Checking results too early can lead to incorrect conclusions.\n",
    "\n",
    "## 9. Limitations\n",
    "- **Sample Bias**: Ensure sample represents the population for accurate results.\n",
    "- **External Factors**: Seasonality, marketing campaigns, or other external influences may affect results.\n",
    "- **Limited Scope**: Results may not generalize beyond the tested population or time frame.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Hypothesis\n",
    "- **Hypothesis**: \"Changing the button color to green will increase the click-through rate by 5%.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Sample Code for A/B Test in Python\n",
    "```python\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Assume data for conversions in control (A) and variant (B)\n",
    "control_conversions = [10, 12, 15, 20]\n",
    "variant_conversions = [12, 14, 18, 25]\n",
    "\n",
    "# T-test to check if there's a significant difference\n",
    "t_stat, p_value = ttest_ind(control_conversions, variant_conversions)\n",
    "print(\"P-Value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35167e11-377c-48b3-82ef-a469699fbb09",
   "metadata": {},
   "source": [
    "## Concepts from LunarTech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cef3ef-4ea3-4cbc-a039-22b9de5846e9",
   "metadata": {},
   "source": [
    "### 1. A/B Basics:\n",
    "Also called split testing................used in business to test :\n",
    "1. new UX features\n",
    "2. new versions of a product\n",
    "3. new versions of an algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a27c4cd-870f-4143-aca9-0a913eb549fb",
   "metadata": {},
   "source": [
    "### 2. Definitions\n",
    "Control Group........exposed to one version or the current version of product\n",
    "Experimental Group.......exposed to second or the new version fo product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bcf8ec-1bec-47cb-8b5b-6c8ea2e85553",
   "metadata": {},
   "source": [
    "## 3. A/B Testing Process\n",
    "1. Hypothesis of A/B Test\n",
    "2. A/B Test Design/ Power Analysis\n",
    "3. Run the A/B test\n",
    "4. Result Analysis/ Statistical Significance\n",
    "5. Result Analysis/ Practical Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5289a3-4ca4-4901-a2fd-49a6adff52c4",
   "metadata": {},
   "source": [
    "## 4. Hypothesis and Primary Metric(Step 1)\n",
    "Business Hypothesis describes what two products are being compared and what is the desired impact or difference for the business\n",
    ". how to fix a potential issue in the product\n",
    ". solution will influence the key performance indicators(KPIs)\n",
    "Example: changing the color of a button to enhance the performance of a customers \n",
    "### Primary Metric:\n",
    "Measure the performance of the product being tested in the A/B test for the experimental and control groups. It will be used to identify whether there is a **statistically significant difference** between these two groups.\n",
    "**NB** \n",
    "There should be a single primary metric\n",
    "Answering the metric validity question\n",
    "\n",
    "### Choosing Primary Metric\n",
    "**Mertric Validity Question** if this chosen metric were to increase significantly while everything else stays constant, would we achieve our goal and address the problem?\n",
    "- higher revenue?\n",
    "- higher engagement?\n",
    "- more views?\n",
    "### Revenue Primary Metric\n",
    "\n",
    "**Conversion rate** = (Number of conversions(purchases made)/ Number of total visitors)x 100%\n",
    "\n",
    "### Engagement Primary Metric\n",
    "\n",
    "**CTR(Click Through Rate)** = (Number of clicks/ Number of impressions) x 100%\n",
    "\n",
    "### Statistical Hypothesis/Hypothesis Testing\n",
    "Statistical procedure that is used to determine whether there is a significant difference between the observed data and the expected data:\n",
    ". to test the results of an experiment\n",
    ". establish statistical significance\n",
    ". put hypothesis subject to reject under Null Hypothesis(H_0)\n",
    ". put hypothesis subject to acceptance under Alternative Hypothesis(H_1)\n",
    "**Example**\n",
    "Null: CTR of **Learn More** button with Blue color is equal to CTR of green button\n",
    "Alternative: CTR of **Learn More** button with Blue color is larger to CTR of green button"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d87657e-8c23-4e7b-bf57-332776242f18",
   "metadata": {},
   "source": [
    "## 5. A/B Test Design(Step 2)\n",
    "### Power Analysis...........................\n",
    "1. Determine **Power** of the test\n",
    "   - probability of correctly rejecting the null hypothesis\n",
    "   - probability of not making a type II error(1-beta)\n",
    "   - beta: Type II error\n",
    "   - common to pick 80% as the **power** of the A/B test\n",
    "### (1-beta): power of the test, beta- probability of type II error\n",
    "### Significance level \n",
    "2. Determine **Significance level** of the test\n",
    "   - probability of correctly rejecting the null hypothesis while the null is true\n",
    "   - detecting statistically significance while it's not\n",
    "   - probability of making a type I error(alpha)\n",
    "   - beta: Type II error\n",
    "   - common to pick 5% as the **significance level** of the test\n",
    "### alpha: probability of Type I error, significance level\n",
    "### Minimum Detectable Effect\n",
    "3. Determine **Minimum Detectable Effect** of the test\n",
    "   - What is the substantive to the statistical significance for the business?\n",
    "   - Proxy that relates to smallest effect that would matter in practice\n",
    "   - No common level - depends on the business ask\n",
    "### delta- minimum detectable effect\n",
    "## Calculating Min Sample Size ## ............................\n",
    "1. Primary metric of A/B testing is in the form of a binary variable\n",
    "2. primary metric of the test is in the form of proportions or averages\n",
    "............\"Complete Guide to A/B testing Design, Implementation and Pitfalls\"........................\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7693c20-eba9-47c0-9b32-0f2c4c23339b",
   "metadata": {},
   "source": [
    "## 3. A/B Test(Step 3)\n",
    "## 4. Results Analysis(step 4)\n",
    "...............**calculating the min sample size**................\n",
    "**H_0: mu_con = mu_exp**\n",
    "**H_1: mu_con != mu_exp**\n",
    "......................**A/B Test Duration**...................\n",
    "#### Duration = N/(# visitors per day)\n",
    "Too small test duration-----------Novelty effects\n",
    "Too large test duration-----------Maturation effects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b44a063-9472-47e2-be0d-29fedbdae594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       click group\n",
      "0          0   exp\n",
      "1          0   exp\n",
      "2          1   exp\n",
      "3          1   exp\n",
      "4          1   exp\n",
      "...      ...   ...\n",
      "19995      1   con\n",
      "19996      1   con\n",
      "19997      1   con\n",
      "19998      1   con\n",
      "19999      1   con\n",
      "\n",
      "[20000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "## Practice:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "# ----------------------------- Simulating Click Data for A/B Testing ------------------------------#\n",
    "N_exp = 10000\n",
    "N_con = 10000\n",
    "\n",
    "# Generating Click Data\n",
    "click_exp = pd.Series(np.random.binomial(1,0.5,size = N_exp))\n",
    "click_con = pd.Series(np.random.binomial(1,0.2,size = N_con))\n",
    "\n",
    "# Generate Group Identifier\n",
    "exp_id = pd.Series(np.repeat(\"exp\", N_exp))\n",
    "con_id = pd.Series(np.repeat(\"con\", N_con))\n",
    "\n",
    "df_exp = pd.concat([click_exp,exp_id],axis = 1)\n",
    "df_con = pd.concat([click_con,con_id],axis = 1)\n",
    "\n",
    "df_exp.columns = [\"click\", \"group\"]\n",
    "df_con.columns = [\"click\", \"group\"]\n",
    "\n",
    "df_ab_test = pd.concat([df_exp, df_con], axis=0).reset_index(drop=True)\n",
    "print(df_ab_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0273af20-1dd2-4fda-8764-441174b42670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['exp', 'con'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ab_test['group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf387b-962a-4768-8526-98789eb714c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ab_test['click'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ad40f75-35d0-4b9a-a051-035e5f966493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group\n",
      "con    2037\n",
      "exp    4922\n",
      "Name: click, dtype: int32\n",
      "Number of CLicks in Control:  2037\n",
      "Number of CLicks in Experimental:  4922\n",
      "Alpha: significance level is: 0.05\n",
      "Click Probability in Control Group: 0.2037\n",
      "Click Probability in Experimental Group: 0.4922\n",
      "p^_pooled is:  0.34795\n",
      "pooled_variance is:  4.53761595e-05\n",
      "Standard Error is:  0.006736182858266245\n",
      "Test Statistics for 2-sample Z-test is: -42.82840980867524\n",
      "Z-critical value from Standard Normal distribution:  1.959963984540054\n",
      "P-value of the 2-sample Z-test:  0.0\n",
      "Confidence Interval of the 2 sample Z-test is:  [0.275, 0.302]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------- Statistical Significance in A/B Testing ------------------------------#\n",
    "# calculating the total number of clicks per group by summing 1's\n",
    "X_con = df_ab_test.groupby(\"group\")[\"click\"].sum().loc[\"con\"]\n",
    "X_exp = df_ab_test.groupby(\"group\")[\"click\"].sum().loc[\"exp\"]\n",
    "\n",
    "# printing this for visibility\n",
    "print(df_ab_test.groupby(\"group\")[\"click\"].sum())\n",
    "print(\"Number of CLicks in Control: \", X_con)\n",
    "print(\"Number of CLicks in Experimental: \", X_exp)\n",
    "\n",
    "# statistical significance level of the test\n",
    "alpha = 0.05\n",
    "print(\"Alpha: significance level is:\", alpha )\n",
    "\n",
    "# computing the estimate of click probability per group\n",
    "p_con_hat = X_con/N_con\n",
    "p_exp_hat = X_exp/N_exp\n",
    "print(\"Click Probability in Control Group:\", p_con_hat)\n",
    "print(\"Click Probability in Experimental Group:\", p_exp_hat)\n",
    "\n",
    "# computing the estimate of pooled clicked probability\n",
    "p_pooled_hat = (X_con+X_exp)/(N_con + N_exp)\n",
    "\n",
    "# computing the estimate of pooled variance\n",
    "pooled_variance = p_pooled_hat * (1-p_pooled_hat) * (1/N_con + 1/N_exp)\n",
    "print(\"p^_pooled is: \", p_pooled_hat)\n",
    "print(\"pooled_variance is: \", pooled_variance)\n",
    "\n",
    "# computing the standard error of the test\n",
    "SE = np.sqrt(pooled_variance)\n",
    "print(\"Standard Error is: \", SE)\n",
    "\n",
    "# computing the test statistics of Z-test\n",
    "Test_stat = (p_con_hat - p_exp_hat)/SE\n",
    "print(\"Test Statistics for 2-sample Z-test is:\", Test_stat)\n",
    "\n",
    "#\n",
    "Z_crit = norm.ppf(1-alpha/2)\n",
    "print(\"Z-critical value from Standard Normal distribution: \", Z_crit)\n",
    "\n",
    "p_value = 2 * norm.sf(abs(Test_stat))\n",
    "print(\"P-value of the 2-sample Z-test: \",round(p_value,3))\n",
    "\n",
    "\n",
    "CI = [round((p_exp_hat - p_con_hat) - SE*Z_crit,3), round((p_exp_hat - p_con_hat) + SE*Z_crit,3)]\n",
    "print(\"Confidence Interval of the 2 sample Z-test is: \", CI)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c6ac7-43e3-4fa0-a78b-ba43e7d1c76d",
   "metadata": {},
   "source": [
    "## A/B Test Insights\n",
    "\n",
    "### 1. Significant Increase in Click-Through Rate\n",
    "- The experimental group’s click-through rate (49.22%) is significantly higher than the control group’s rate (20.37%).\n",
    "- This difference indicates that the change implemented in the experimental setup (e.g., a new feature, design, or wording) positively impacted user engagement.\n",
    "\n",
    "### 2. Strong Statistical Significance\n",
    "- The test yielded a Z-score of -42.83, far exceeding the Z-critical threshold of 1.96 for a 5% significance level.\n",
    "- The p-value of approximately 0.0 is well below the 0.05 threshold, meaning the observed difference is very unlikely to be due to chance.\n",
    "\n",
    "### 3. Robust Confidence Interval\n",
    "- The 95% confidence interval for the difference in click rates is [0.275, 0.302], suggesting with high confidence that the experimental setup improves the click rate by 27.5% to 30.2%.\n",
    "- This entirely positive interval supports the reliability of the experimental group's improved performance.\n",
    "\n",
    "### 4. Practical Impact\n",
    "- The experimental setup not only shows statistical significance but also a meaningful practical impact, with nearly double the click-through rate compared to the control group.\n",
    "- Implementing the change could lead to substantial improvements in user engagement, conversions, or other relevant metrics.\n",
    "\n",
    "## Recommendations\n",
    "- **Roll Out the Change**: Given the strong statistical and practical significance, it’s advisable to adopt the experimental setup widely.\n",
    "- **Further Testing**: Consider testing variations of the successful experimental setup to refine and optimize its effectiveness further.\n",
    "- **Monitor Performance**: After deployment, continuously monitor click-through rates to ensure sustained improvement, adjusting for any seasonal or external influences over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36842186-e0e4-44c8-8266-be2aa22ec3d6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f6259-7824-4c3a-b5eb-2fdb6c0e46c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a3aa5-d331-4014-8d57-5e541fe488e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
